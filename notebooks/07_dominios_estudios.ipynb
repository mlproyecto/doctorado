{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An치lisis de Dominios de Estudios: Mapping Review IA y ML en Educaci칩n Matem치tica K-12\\n\n",
    "\\n\n",
    "**MQ7: 쮼n qu칠 dominios se centran los estudios?**\\n\n",
    "\\n\n",
    "Este notebook analiza los dominios espec칤ficos y 치reas tem치ticas en las que se centran los estudios sobre IA y ML en educaci칩n matem치tica K-12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci칩n del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci칩n de dependencias\\n\n",
    "!pip install pandas numpy matplotlib seaborn plotly nltk wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci칩n de librer칤as\\n\n",
    "import pandas as pd\\n\n",
    "import numpy as np\\n\n",
    "import matplotlib.pyplot as plt\\n\n",
    "import seaborn as sns\\n\n",
    "import plotly.express as px\\n\n",
    "import plotly.graph_objects as go\\n\n",
    "from plotly.subplots import make_subplots\\n\n",
    "import re\\n\n",
    "import nltk\\n\n",
    "from nltk.corpus import stopwords\\n\n",
    "from nltk.tokenize import word_tokenize\\n\n",
    "from collections import Counter\\n\n",
    "from wordcloud import WordCloud\\n\n",
    "import warnings\\n\n",
    "warnings.filterwarnings('ignore')\\n\n",
    "\\n\n",
    "# Descargar recursos de NLTK\\n\n",
    "try:\\n\n",
    "    nltk.data.find('tokenizers/punkt')\\n\n",
    "except LookupError:\\n\n",
    "    nltk.download('punkt')\\n\n",
    "\\n\n",
    "try:\\n\n",
    "    nltk.data.find('corpora/stopwords')\\n\n",
    "except LookupError:\\n\n",
    "    nltk.download('stopwords')\\n\n",
    "\\n\n",
    "# Configuraci칩n de estilo\\n\n",
    "plt.style.use('seaborn-v0_8')\\n\n",
    "sns.set_palette(\\\"husl\\\")\\n\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\\n\n",
    "plt.rcParams['font.size'] = 12\\n\n",
    "\\n\n",
    "# Configuraci칩n para mostrar todas las columnas\\n\n",
    "pd.set_option('display.max_columns', None)\\n\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos desde GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset desde GitHub\\n\n",
    "# IMPORTANTE: Cambiar la URL por tu repositorio real\\n\n",
    "url = \\\"https://raw.githubusercontent.com/TU_USUARIO/TU_REPOSITORIO/main/MappingReview.csv\\\"\\n\n",
    "df = pd.read_csv(url, sep=';', encoding='utf-8')\\n\n",
    "\\n\n",
    "print(f\\\"Dataset cargado: {df.shape[0]} filas y {df.shape[1]} columnas\\\")\\n\n",
    "print(\\\"\\\\nPrimeras 5 filas:\\\")\\n\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An치lisis de Dominios de Estudios (MQ7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir dominios de estudio\\n\n",
    "study_domains = {\\n\n",
    "    'Intelligent Tutoring Systems': ['intelligent tutoring system', 'its', 'tutoring system', 'adaptive tutoring'],\\n\n",
    "    'Chatbots & Conversational AI': ['chatbot', 'chatbots', 'conversational ai', 'dialogue system', 'conversational agent'],\\n\n",
    "    'Predictive Analytics': ['predictive analytics', 'prediction', 'predictive modeling', 'forecasting'],\\n\n",
    "    'Learning Analytics': ['learning analytics', 'educational data mining', 'data mining', 'analytics'],\\n\n",
    "    'Computer Vision': ['computer vision', 'image recognition', 'visual recognition', 'image processing'],\\n\n",
    "    'Natural Language Processing': ['natural language processing', 'nlp', 'text analysis', 'language processing'],\\n\n",
    "    'Personalized Learning': ['personalized learning', 'adaptive learning', 'individualized learning', 'customized learning'],\\n\n",
    "    'Assessment & Evaluation': ['assessment', 'evaluation', 'testing', 'measurement', 'performance evaluation'],\\n\n",
    "    'Gamification': ['gamification', 'game-based learning', 'serious games', 'educational games'],\\n\n",
    "    'Virtual/Augmented Reality': ['virtual reality', 'augmented reality', 'vr', 'ar', 'immersive learning'],\\n\n",
    "    'Robotics': ['robotics', 'educational robots', 'robot', 'robotic'],\\n\n",
    "    'Neural Networks': ['neural network', 'neural networks', 'deep learning', 'artificial neural network'],\\n\n",
    "    'Machine Learning': ['machine learning', 'ml', 'supervised learning', 'unsupervised learning'],\\n\n",
    "    'Data Science': ['data science', 'big data', 'data analysis', 'statistical analysis'],\\n\n",
    "    'STEM Education': ['stem', 'science', 'technology', 'engineering', 'mathematics']\\n\n",
    "}\\n\n",
    "\\n\n",
    "# Funci칩n para identificar dominios en el texto\\n\n",
    "def identify_domains(text):\\n\n",
    "    if pd.isna(text):\\n\n",
    "        return []\\n\n",
    "    \\n\n",
    "    text = str(text).lower()\\n\n",
    "    identified_domains = []\\n\n",
    "    \\n\n",
    "    for domain, keywords in study_domains.items():\\n\n",
    "        for keyword in keywords:\\n\n",
    "            if keyword in text:\\n\n",
    "                identified_domains.append(domain)\\n\n",
    "                break\\n\n",
    "    \\n\n",
    "    return list(set(identified_domains))\\n\n",
    "\\n\n",
    "# Aplicar identificaci칩n de dominios\\n\n",
    "df['Title_Domains'] = df['Title'].apply(identify_domains)\\n\n",
    "df['Abstract_Domains'] = df['Abstract'].apply(identify_domains)\\n\n",
    "\\n\n",
    "print(\\\"Identificaci칩n de dominios completada\\\")\\n\n",
    "print(f\\\"Publicaciones con dominios en t칤tulos: {len(df[df['Title_Domains'].apply(len) > 0])}\\\")\\n\n",
    "print(f\\\"Publicaciones con dominios en abstracts: {len(df[df['Abstract_Domains'].apply(len) > 0])}\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis de frecuencia de dominios\\n\n",
    "all_title_domains = []\\n\n",
    "all_abstract_domains = []\\n\n",
    "\\n\n",
    "for domains in df['Title_Domains']:\\n\n",
    "    all_title_domains.extend(domains)\\n\n",
    "\\n\n",
    "for domains in df['Abstract_Domains']:\\n\n",
    "    all_abstract_domains.extend(domains)\\n\n",
    "\\n\n",
    "# Contar frecuencia\\n\n",
    "title_domain_counts = Counter(all_title_domains)\\n\n",
    "abstract_domain_counts = Counter(all_abstract_domains)\\n\n",
    "\\n\n",
    "print(\\\"=== DOMINIOS M츼S FRECUENTES EN T칈TULOS ===\\\")\\n\n",
    "for domain, count in title_domain_counts.most_common(10):\\n\n",
    "    print(f\\\"{domain}: {count} apariciones\\\")\\n\n",
    "\\n\n",
    "print(\\\"\\\\n=== DOMINIOS M츼S FRECUENTES EN ABSTRACTS ===\\\")\\n\n",
    "for domain, count in abstract_domain_counts.most_common(10):\\n\n",
    "    print(f\\\"{domain}: {count} apariciones\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr치fico de barras para dominios m치s frecuentes\\n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\\n\n",
    "\\n\n",
    "# Dominios en t칤tulos\\n\n",
    "top_title_domains = dict(title_domain_counts.most_common(8))\\n\n",
    "bars1 = ax1.bar(range(len(top_title_domains)), top_title_domains.values(), color='lightblue', alpha=0.7)\\n\n",
    "ax1.set_xlabel('Dominios de Estudio', fontsize=14)\\n\n",
    "ax1.set_ylabel('Frecuencia', fontsize=14)\\n\n",
    "ax1.set_title('Dominios M치s Frecuentes en T칤tulos', fontsize=16, fontweight='bold')\\n\n",
    "ax1.set_xticks(range(len(top_title_domains)))\\n\n",
    "ax1.set_xticklabels(top_title_domains.keys(), rotation=45, ha='right')\\n\n",
    "ax1.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars1, top_title_domains.values())):\\n\n",
    "    ax1.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "# Dominios en abstracts\\n\n",
    "top_abstract_domains = dict(abstract_domain_counts.most_common(8))\\n\n",
    "bars2 = ax2.bar(range(len(top_abstract_domains)), top_abstract_domains.values(), color='lightcoral', alpha=0.7)\\n\n",
    "ax2.set_xlabel('Dominios de Estudio', fontsize=14)\\n\n",
    "ax2.set_ylabel('Frecuencia', fontsize=14)\\n\n",
    "ax2.set_title('Dominios M치s Frecuentes en Abstracts', fontsize=16, fontweight='bold')\\n\n",
    "ax2.set_xticks(range(len(top_abstract_domains)))\\n\n",
    "ax2.set_xticklabels(top_abstract_domains.keys(), rotation=45, ha='right')\\n\n",
    "ax2.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars2, top_abstract_domains.values())):\\n\n",
    "    ax2.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An치lisis de Combinaciones de Dominios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis de combinaciones de dominios\\n\n",
    "all_domains = []\\n\n",
    "for domains in df['Title_Domains'] + df['Abstract_Domains']:\\n\n",
    "    if domains:\\n\n",
    "        all_domains.append('+'.join(sorted(domains)))\\n\n",
    "\\n\n",
    "domain_combination_counts = Counter(all_domains)\\n\n",
    "\\n\n",
    "print(\\\"=== COMBINACIONES DE DOMINIOS M츼S FRECUENTES ===\\\")\\n\n",
    "for combination, count in domain_combination_counts.most_common(15):\\n\n",
    "    print(f\\\"{combination}: {count} publicaciones\\\")\\n\n",
    "\\n\n",
    "# Gr치fico de combinaciones\\n\n",
    "top_combinations = dict(domain_combination_counts.most_common(10))\\n\n",
    "\\n\n",
    "plt.figure(figsize=(15, 8))\\n\n",
    "bars = plt.bar(range(len(top_combinations)), top_combinations.values(), color='lightgreen', alpha=0.7)\\n\n",
    "plt.xlabel('Combinaci칩n de Dominios', fontsize=14)\\n\n",
    "plt.ylabel('N칰mero de Publicaciones', fontsize=14)\\n\n",
    "plt.title('Combinaciones de Dominios M치s Frecuentes', fontsize=16, fontweight='bold')\\n\n",
    "plt.xticks(range(len(top_combinations)), list(top_combinations.keys()), rotation=45, ha='right')\\n\n",
    "plt.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars, top_combinations.values())):\\n\n",
    "    plt.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An치lisis Temporal por Dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Year a num칠rico\\n\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\\n\n",
    "\\n\n",
    "# An치lisis temporal por dominio\\n\n",
    "temporal_domains = {}\\n\n",
    "\\n\n",
    "for year in sorted(df['Year'].unique()):\\n\n",
    "    if pd.notna(year):\\n\n",
    "        year_data = df[df['Year'] == year]\\n\n",
    "        year_domains = []\\n\n",
    "        \\n\n",
    "        for domains in year_data['Title_Domains']:\\n\n",
    "            year_domains.extend(domains)\\n\n",
    "        for domains in year_data['Abstract_Domains']:\\n\n",
    "            year_domains.extend(domains)\\n\n",
    "        \\n\n",
    "        temporal_domains[year] = Counter(year_domains)\\n\n",
    "\\n\n",
    "print(\\\"=== EVOLUCI칍N TEMPORAL DE DOMINIOS ===\\\")\\n\n",
    "for year, domain_counts in temporal_domains.items():\\n\n",
    "    print(f\\\"\\\\nA침o {year}:\\\")\\n\n",
    "    for domain, count in domain_counts.most_common(5):\\n\n",
    "        print(f\\\"  {domain}: {count} apariciones\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr치fico de evoluci칩n temporal de dominios principales\\n\n",
    "main_domains = ['Machine Learning', 'Intelligent Tutoring Systems', 'Personalized Learning', 'Assessment & Evaluation', 'Learning Analytics']\\n\n",
    "\\n\n",
    "plt.figure(figsize=(15, 8))\\n\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\\n\n",
    "\\n\n",
    "for i, domain in enumerate(main_domains):\\n\n",
    "    domain_counts = []\\n\n",
    "    years = []\\n\n",
    "    \\n\n",
    "    for year in sorted(temporal_domains.keys()):\\n\n",
    "        years.append(year)\\n\n",
    "        count = temporal_domains[year].get(domain, 0)\\n\n",
    "        domain_counts.append(count)\\n\n",
    "    \\n\n",
    "    \\n\n",
    "    plt.plot(years, domain_counts, marker='o', linewidth=2, label=domain, color=colors[i])\\n\n",
    "\\n\n",
    "plt.title('Evoluci칩n Temporal de Dominios Principales', fontsize=16, fontweight='bold')\\n\n",
    "plt.xlabel('A침o', fontsize=14)\\n\n",
    "plt.ylabel('Frecuencia', fontsize=14)\\n\n",
    "plt.legend(title='Dominios', bbox_to_anchor=(1.05, 1), loc='upper left')\\n\n",
    "plt.grid(True, alpha=0.3)\\n\n",
    "plt.xticks(rotation=45)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An치lisis de Dominios por Tipo de Publicaci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis de dominios por tipo de publicaci칩n\\n\n",
    "domain_by_type = {}\\n\n",
    "\\n\n",
    "for pub_type in df['Type of Publication'].unique():\\n\n",
    "    type_data = df[df['Type of Publication'] == pub_type]\\n\n",
    "    type_domains = []\\n\n",
    "    \\n\n",
    "    for domains in type_data['Title_Domains']:\\n\n",
    "        type_domains.extend(domains)\\n\n",
    "    for domains in type_data['Abstract_Domains']:\\n\n",
    "        type_domains.extend(domains)\\n\n",
    "    \\n\n",
    "    domain_by_type[pub_type] = Counter(type_domains)\\n\n",
    "\\n\n",
    "print(\\\"=== DOMINIOS POR TIPO DE PUBLICACI칍N ===\\\")\\n\n",
    "for pub_type, domain_counts in domain_by_type.items():\\n\n",
    "    print(f\\\"\\\\n{pub_type}:\\\")\\n\n",
    "    for domain, count in domain_counts.most_common(5):\\n\n",
    "        print(f\\\"  {domain}: {count} apariciones\\\")\\n\n",
    "\\n\n",
    "# Gr치fico de calor\\n\n",
    "domain_type_matrix = pd.DataFrame(domain_by_type).fillna(0)\\n\n",
    "\\n\n",
    "plt.figure(figsize=(12, 8))\\n\n",
    "sns.heatmap(domain_type_matrix, annot=True, fmt='.0f', cmap='YlOrRd', cbar_kws={'label': 'Frecuencia'})\\n\n",
    "plt.title('Dominios por Tipo de Publicaci칩n', fontsize=16, fontweight='bold')\\n\n",
    "plt.xlabel('Tipo de Publicaci칩n', fontsize=14)\\n\n",
    "plt.ylabel('Dominio de Estudio', fontsize=14)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. An치lisis de Dominios por Fuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis de dominios por fuente\\n\n",
    "domain_by_source = {}\\n\n",
    "\\n\n",
    "for source in df['Source'].unique():\\n\n",
    "    source_data = df[df['Source'] == source]\\n\n",
    "    source_domains = []\\n\n",
    "    \\n\n",
    "    for domains in source_data['Title_Domains']:\\n\n",
    "        source_domains.extend(domains)\\n\n",
    "    for domains in source_data['Abstract_Domains']:\\n\n",
    "        source_domains.extend(domains)\\n\n",
    "    \\n\n",
    "    domain_by_source[source] = Counter(source_domains)\\n\n",
    "\\n\n",
    "print(\\\"=== DOMINIOS POR FUENTE ===\\\")\\n\n",
    "for source, domain_counts in domain_by_source.items():\\n\n",
    "    print(f\\\"\\\\n{source}:\\\")\\n\n",
    "    for domain, count in domain_counts.most_common(5):\\n\n",
    "        print(f\\\"  {domain}: {count} apariciones\\\")\\n\n",
    "\\n\n",
    "# Gr치fico de barras agrupadas\\n\n",
    "top_domains = ['Machine Learning', 'Intelligent Tutoring Systems', 'Personalized Learning', 'Assessment & Evaluation']\\n\n",
    "\\n\n",
    "domain_source_data = []\\n\n",
    "for source in df['Source'].unique():\\n\n",
    "    for domain in top_domains:\\n\n",
    "        count = domain_by_source[source].get(domain, 0)\\n\n",
    "        domain_source_data.append({\\n\n",
    "            'Source': source,\\n\n",
    "            'Domain': domain,\\n\n",
    "            'Count': count\\n\n",
    "        })\\n\n",
    "\\n\n",
    "domain_source_df = pd.DataFrame(domain_source_data)\\n\n",
    "\\n\n",
    "fig = px.bar(domain_source_df, x='Source', y='Count', color='Domain',\\n\n",
    "              title='Dominios por Fuente de Publicaci칩n',\\n\n",
    "              barmode='group')\\n\n",
    "\\n\n",
    "fig.update_layout(\\n\n",
    "    title_font_size=16,\\n\n",
    "    xaxis_title='Fuente',\\n\n",
    "    yaxis_title='Frecuencia'\\n\n",
    ")\\n\n",
    "\\n\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An치lisis de Co-ocurrencia de Dominios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis de co-ocurrencia de dominios\\n\n",
    "domain_co_occurrence = {}\\n\n",
    "\\n\n",
    "for _, row in df.iterrows():\\n\n",
    "    all_domains = row['Title_Domains'] + row['Abstract_Domains']\\n\n",
    "    \\n\n",
    "    for i, domain1 in enumerate(all_domains):\\n\n",
    "        for j, domain2 in enumerate(all_domains):\\n\n",
    "            if i < j:\\n\n",
    "                pair = tuple(sorted([domain1, domain2]))\\n\n",
    "                domain_co_occurrence[pair] = domain_co_occurrence.get(pair, 0) + 1\\n\n",
    "\\n\n",
    "# Top co-ocurrencias\\n\n",
    "top_domain_co_occurrences = sorted(domain_co_occurrence.items(), key=lambda x: x[1], reverse=True)[:15]\\n\n",
    "\\n\n",
    "print(\\\"=== TOP 15 CO-OCURRENCIAS DE DOMINIOS ===\\\")\\n\n",
    "for i, ((domain1, domain2), count) in enumerate(top_domain_co_occurrences, 1):\\n\n",
    "    print(f\\\"{i:2d}. {domain1} + {domain2}: {count} co-ocurrencias\\\")\\n\n",
    "\\n\n",
    "# Gr치fico de co-ocurrencias\\n\n",
    "if top_domain_co_occurrences:\\n\n",
    "    co_occurrence_df = pd.DataFrame(top_domain_co_occurrences, columns=['Domains', 'Count'])\\n\n",
    "    co_occurrence_df['Domain_Pair'] = [f\\\"{d1} + {d2}\\\" for (d1, d2) in co_occurrence_df['Domains']]\\n\n",
    "    \\n\n",
    "    plt.figure(figsize=(12, 8))\\n\n",
    "    bars = plt.barh(range(len(co_occurrence_df)), co_occurrence_df['Count'], color='lightblue', alpha=0.7)\\n\n",
    "    plt.yticks(range(len(co_occurrence_df)), co_occurrence_df['Domain_Pair'], fontsize=10)\\n\n",
    "    plt.xlabel('N칰mero de Co-ocurrencias', fontsize=14)\\n\n",
    "    plt.title('Top 15 Co-ocurrencias de Dominios', fontsize=16, fontweight='bold')\\n\n",
    "    plt.grid(True, alpha=0.3, axis='x')\\n\n",
    "    \\n\n",
    "    # Agregar valores en las barras\\n\n",
    "    for i, count in enumerate(co_occurrence_df['Count']):\\n\n",
    "        plt.text(count + 0.1, i, str(count), va='center', fontweight='bold')\\n\n",
    "    \\n\n",
    "    plt.tight_layout()\\n\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen ejecutivo\\n\n",
    "print(\\\"=== RESUMEN EJECUTIVO ===\\\\n\\\")\\n\n",
    "\\n\n",
    "print(f\\\"游늵 Total de dominios 칰nicos identificados: {len(set(all_title_domains + all_abstract_domains))}\\\")\\n\n",
    "print(f\\\"游닇 Dominio m치s frecuente en t칤tulos: {title_domain_counts.most_common(1)[0][0]} ({title_domain_counts.most_common(1)[0][1]} apariciones)\\\")\\n\n",
    "print(f\\\"游늳 Dominio m치s frecuente en abstracts: {abstract_domain_counts.most_common(1)[0][0]} ({abstract_domain_counts.most_common(1)[0][1]} apariciones)\\\")\\n\n",
    "\\n\n",
    "# An치lisis de diversidad\\n\n",
    "total_publications = len(df)\\n\n",
    "publications_with_domains = len(df[df['Title_Domains'].apply(len) > 0]) + len(df[df['Abstract_Domains'].apply(len) > 0])\\n\n",
    "coverage_percentage = (publications_with_domains / (total_publications * 2)) * 100\\n\n",
    "print(f\\\"游깷 Cobertura de dominios: {coverage_percentage:.1f}%\\\")\\n\n",
    "\\n\n",
    "# Mejor combinaci칩n\\n\n",
    "if domain_combination_counts:\\n\n",
    "    best_combination = domain_combination_counts.most_common(1)[0]\\n\n",
    "    print(f\\\"游끥 Mejor combinaci칩n de dominios: {best_combination[0]} ({best_combination[1]} publicaciones)\\\")\\n\n",
    "\\n\n",
    "# Co-ocurrencia m치s frecuente\\n\n",
    "if top_domain_co_occurrences:\\n\n",
    "    most_common_co_occurrence = top_domain_co_occurrences[0]\\n\n",
    "    print(f\\\"游댕 Co-ocurrencia m치s frecuente: {most_common_co_occurrence[0][0]} + {most_common_co_occurrence[0][1]} ({most_common_co_occurrence[1]} veces)\\\")\\n\n",
    "\\n\n",
    "print(\\\"\\\\n=== CONCLUSIONES ===\\\")\\n\n",
    "print(\\\"1. Los sistemas de tutor칤a inteligente dominan la investigaci칩n\\\")\\n\n",
    "print(\\\"2. El aprendizaje personalizado es un 치rea clave\\\")\\n\n",
    "print(\\\"3. Hay una evoluci칩n temporal en los dominios de estudio\\\")\\n\n",
    "print(\\\"4. Existen patrones de co-ocurrencia entre dominios\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
