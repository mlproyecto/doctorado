{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis de T√©rminos de B√∫squeda: Mapping Review IA y ML en Educaci√≥n Matem√°tica K-12\\n\n",
    "\\n\n",
    "**MQ6: ¬øQu√© t√©rminos de b√∫squeda se utilizan para definir la cadena de b√∫squeda en este tipo de estudios?**\\n\n",
    "\\n\n",
    "Este notebook analiza los t√©rminos de b√∫squeda y palabras clave utilizados en los estudios sobre IA y ML en educaci√≥n matem√°tica K-12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de dependencias\\n\n",
    "!pip install pandas numpy matplotlib seaborn plotly nltk wordcloud textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n de librer√≠as\\n\n",
    "import pandas as pd\\n\n",
    "import numpy as np\\n\n",
    "import matplotlib.pyplot as plt\\n\n",
    "import seaborn as sns\\n\n",
    "import plotly.express as px\\n\n",
    "import plotly.graph_objects as go\\n\n",
    "from plotly.subplots import make_subplots\\n\n",
    "import re\\n\n",
    "import nltk\\n\n",
    "from nltk.corpus import stopwords\\n\n",
    "from nltk.tokenize import word_tokenize\\n\n",
    "from collections import Counter\\n\n",
    "from wordcloud import WordCloud\\n\n",
    "from textblob import TextBlob\\n\n",
    "import warnings\\n\n",
    "warnings.filterwarnings('ignore')\\n\n",
    "\\n\n",
    "# Descargar recursos de NLTK\\n\n",
    "try:\\n\n",
    "    nltk.data.find('tokenizers/punkt')\\n\n",
    "except LookupError:\\n\n",
    "    nltk.download('punkt')\\n\n",
    "\\n\n",
    "try:\\n\n",
    "    nltk.data.find('corpora/stopwords')\\n\n",
    "except LookupError:\\n\n",
    "    nltk.download('stopwords')\\n\n",
    "\\n\n",
    "# Configuraci√≥n de estilo\\n\n",
    "plt.style.use('seaborn-v0_8')\\n\n",
    "sns.set_palette(\\\"husl\\\")\\n\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\\n\n",
    "plt.rcParams['font.size'] = 12\\n\n",
    "\\n\n",
    "# Configuraci√≥n para mostrar todas las columnas\\n\n",
    "pd.set_option('display.max_columns', None)\\n\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos desde GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset desde GitHub\\n\n",
    "# IMPORTANTE: Cambiar la URL por tu repositorio real\\n\n",
    "url = \\\"https://raw.githubusercontent.com/TU_USUARIO/TU_REPOSITORIO/main/MappingReview.csv\\\"\\n\n",
    "df = pd.read_csv(url, sep=';', encoding='utf-8')\\n\n",
    "\\n\n",
    "print(f\\\"Dataset cargado: {df.shape[0]} filas y {df.shape[1]} columnas\\\")\\n\n",
    "print(\\\"\\\\nPrimeras 5 filas:\\\")\\n\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis de T√©rminos de B√∫squeda (MQ6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para extraer t√©rminos de b√∫squeda de t√≠tulos y abstracts\\n\n",
    "def extract_search_terms(text):\\n\n",
    "    if pd.isna(text):\\n\n",
    "        return []\\n\n",
    "    \\n\n",
    "    # Convertir a min√∫sculas\\n\n",
    "    text = str(text).lower()\\n\n",
    "    \\n\n",
    "    # Definir t√©rminos de b√∫squeda relevantes\\n\n",
    "    search_terms = [\\n\n",
    "        'artificial intelligence', 'ai', 'machine learning', 'ml', 'deep learning',\\n\n",
    "        'neural network', 'neural networks', 'intelligent tutoring system', 'its',\\n\n",
    "        'chatbot', 'chatbots', 'natural language processing', 'nlp',\\n\n",
    "        'computer vision', 'predictive analytics', 'data mining',\\n\n",
    "        'mathematics', 'math', 'mathematical', 'algebra', 'geometry', 'calculus',\\n\n",
    "        'k-12', 'k12', 'primary education', 'secondary education',\\n\n",
    "        'elementary', 'middle school', 'high school', 'primary school',\\n\n",
    "        'student', 'students', 'teacher', 'teachers', 'classroom',\\n\n",
    "        'learning', 'teaching', 'education', 'educational',\\n\n",
    "        'assessment', 'evaluation', 'performance', 'achievement',\\n\n",
    "        'personalized', 'adaptive', 'individualized', 'customized',\\n\n",
    "        'stem', 'science', 'technology', 'engineering',\\n\n",
    "        'digital', 'online', 'virtual', 'remote', 'distance learning'\\n\n",
    "    ]\\n\n",
    "    \\n\n",
    "    found_terms = []\\n\n",
    "    for term in search_terms:\\n\n",
    "        if term in text:\\n\n",
    "            found_terms.append(term)\\n\n",
    "    \\n\n",
    "    return found_terms\\n\n",
    "\\n\n",
    "# Aplicar extracci√≥n a t√≠tulos y abstracts\\n\n",
    "df['Title_Terms'] = df['Title'].apply(extract_search_terms)\\n\n",
    "df['Abstract_Terms'] = df['Abstract'].apply(extract_search_terms)\\n\n",
    "\\n\n",
    "print(\\\"Extracci√≥n de t√©rminos de b√∫squeda completada\\\")\\n\n",
    "print(f\\\"Publicaciones con t√©rminos en t√≠tulos: {len(df[df['Title_Terms'].apply(len) > 0])}\\\")\\n\n",
    "print(f\\\"Publicaciones con t√©rminos en abstracts: {len(df[df['Abstract_Terms'].apply(len) > 0])}\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de frecuencia de t√©rminos\\n\n",
    "all_title_terms = []\\n\n",
    "all_abstract_terms = []\\n\n",
    "\\n\n",
    "for terms in df['Title_Terms']:\\n\n",
    "    all_title_terms.extend(terms)\\n\n",
    "\\n\n",
    "for terms in df['Abstract_Terms']:\\n\n",
    "    all_abstract_terms.extend(terms)\\n\n",
    "\\n\n",
    "# Contar frecuencia\\n\n",
    "title_term_counts = Counter(all_title_terms)\\n\n",
    "abstract_term_counts = Counter(all_abstract_terms)\\n\n",
    "\\n\n",
    "print(\\\"=== T√âRMINOS M√ÅS FRECUENTES EN T√çTULOS ===\\\")\\n\n",
    "for term, count in title_term_counts.most_common(15):\\n\n",
    "    print(f\\\"{term}: {count} apariciones\\\")\\n\n",
    "\\n\n",
    "print(\\\"\\\\n=== T√âRMINOS M√ÅS FRECUENTES EN ABSTRACTS ===\\\")\\n\n",
    "for term, count in abstract_term_counts.most_common(15):\\n\n",
    "    print(f\\\"{term}: {count} apariciones\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de barras para t√©rminos m√°s frecuentes\\n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\\n\n",
    "\\n\n",
    "# T√©rminos en t√≠tulos\\n\n",
    "top_title_terms = dict(title_term_counts.most_common(10))\\n\n",
    "bars1 = ax1.bar(range(len(top_title_terms)), top_title_terms.values(), color='lightblue', alpha=0.7)\\n\n",
    "ax1.set_xlabel('T√©rminos de B√∫squeda', fontsize=14)\\n\n",
    "ax1.set_ylabel('Frecuencia', fontsize=14)\\n\n",
    "ax1.set_title('T√©rminos M√°s Frecuentes en T√≠tulos', fontsize=16, fontweight='bold')\\n\n",
    "ax1.set_xticks(range(len(top_title_terms)))\\n\n",
    "ax1.set_xticklabels(top_title_terms.keys(), rotation=45, ha='right')\\n\n",
    "ax1.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars1, top_title_terms.values())):\\n\n",
    "    ax1.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "# T√©rminos en abstracts\\n\n",
    "top_abstract_terms = dict(abstract_term_counts.most_common(10))\\n\n",
    "bars2 = ax2.bar(range(len(top_abstract_terms)), top_abstract_terms.values(), color='lightcoral', alpha=0.7)\\n\n",
    "ax2.set_xlabel('T√©rminos de B√∫squeda', fontsize=14)\\n\n",
    "ax2.set_ylabel('Frecuencia', fontsize=14)\\n\n",
    "ax2.set_title('T√©rminos M√°s Frecuentes en Abstracts', fontsize=16, fontweight='bold')\\n\n",
    "ax2.set_xticks(range(len(top_abstract_terms)))\\n\n",
    "ax2.set_xticklabels(top_abstract_terms.keys(), rotation=45, ha='right')\\n\n",
    "ax2.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars2, top_abstract_terms.values())):\\n\n",
    "    ax2.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An√°lisis de Palabras Clave y Nubes de Palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para limpiar texto para nube de palabras\\n\n",
    "def clean_text_for_wordcloud(text):\\n\n",
    "    if pd.isna(text):\\n\n",
    "        return ''\\n\n",
    "    \\n\n",
    "    # Convertir a min√∫sculas\\n\n",
    "    text = str(text).lower()\\n\n",
    "    \\n\n",
    "    # Remover caracteres especiales\\n\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\\n\n",
    "    \\n\n",
    "    # Tokenizar\\n\n",
    "    tokens = word_tokenize(text)\\n\n",
    "    \\n\n",
    "    # Remover stopwords\\n\n",
    "    stop_words = set(stopwords.words('english'))\\n\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\\n\n",
    "    \\n\n",
    "    return ' '.join(tokens)\\n\n",
    "\\n\n",
    "# Crear texto combinado para nube de palabras\\n\n",
    "all_titles = ' '.join(df['Title'].fillna('').astype(str))\\n\n",
    "all_abstracts = ' '.join(df['Abstract'].fillna('').astype(str))\\n\n",
    "\\n\n",
    "# Limpiar texto\\n\n",
    "clean_titles = clean_text_for_wordcloud(all_titles)\\n\n",
    "clean_abstracts = clean_text_for_wordcloud(all_abstracts)\\n\n",
    "\\n\n",
    "print(\\\"Texto procesado para nubes de palabras\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar nubes de palabras\\n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\\n\n",
    "\\n\n",
    "# Nube de palabras para t√≠tulos\\n\n",
    "wordcloud_titles = WordCloud(width=800, height=400, background_color='white', \\n\n",
    "                            max_words=100, colormap='viridis').generate(clean_titles)\\n\n",
    "ax1.imshow(wordcloud_titles, interpolation='bilinear')\\n\n",
    "ax1.axis('off')\\n\n",
    "ax1.set_title('Nube de Palabras - T√≠tulos', fontsize=16, fontweight='bold')\\n\n",
    "\\n\n",
    "# Nube de palabras para abstracts\\n\n",
    "wordcloud_abstracts = WordCloud(width=800, height=400, background_color='white', \\n\n",
    "                               max_words=100, colormap='plasma').generate(clean_abstracts)\\n\n",
    "ax2.imshow(wordcloud_abstracts, interpolation='bilinear')\\n\n",
    "ax2.axis('off')\\n\n",
    "ax2.set_title('Nube de Palabras - Abstracts', fontsize=16, fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Categor√≠as de T√©rminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir categor√≠as de t√©rminos\\n\n",
    "term_categories = {\\n\n",
    "    'AI_ML': ['artificial intelligence', 'ai', 'machine learning', 'ml', 'deep learning', 'neural network', 'neural networks'],\\n\n",
    "    'Education': ['education', 'educational', 'learning', 'teaching', 'student', 'students', 'teacher', 'teachers', 'classroom'],\\n\n",
    "    'Mathematics': ['mathematics', 'math', 'mathematical', 'algebra', 'geometry', 'calculus'],\\n\n",
    "    'K12': ['k-12', 'k12', 'primary education', 'secondary education', 'elementary', 'middle school', 'high school', 'primary school'],\\n\n",
    "    'Technology': ['intelligent tutoring system', 'its', 'chatbot', 'chatbots', 'natural language processing', 'nlp', 'computer vision'],\\n\n",
    "    'Assessment': ['assessment', 'evaluation', 'performance', 'achievement'],\\n\n",
    "    'Personalization': ['personalized', 'adaptive', 'individualized', 'customized'],\\n\n",
    "    'STEM': ['stem', 'science', 'technology', 'engineering'],\\n\n",
    "    'Digital': ['digital', 'online', 'virtual', 'remote', 'distance learning']\\n\n",
    "}\\n\n",
    "\\n\n",
    "# Contar t√©rminos por categor√≠a\\n\n",
    "category_counts = {}\\n\n",
    "for category, terms in term_categories.items():\\n\n",
    "    count = 0\\n\n",
    "    for term in terms:\\n\n",
    "        count += title_term_counts.get(term, 0) + abstract_term_counts.get(term, 0)\\n\n",
    "    category_counts[category] = count\\n\n",
    "\\n\n",
    "print(\\\"=== FRECUENCIA POR CATEGOR√çA DE T√âRMINOS ===\\\")\\n\n",
    "for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\\n\n",
    "    print(f\\\"{category}: {count} apariciones\\\")\\n\n",
    "\\n\n",
    "# Gr√°fico de barras para categor√≠as\\n\n",
    "plt.figure(figsize=(12, 8))\\n\n",
    "bars = plt.bar(range(len(category_counts)), list(category_counts.values()), color='lightgreen', alpha=0.7)\\n\n",
    "plt.xlabel('Categor√≠a de T√©rminos', fontsize=14)\\n\n",
    "plt.ylabel('Frecuencia Total', fontsize=14)\\n\n",
    "plt.title('Frecuencia de T√©rminos por Categor√≠a', fontsize=16, fontweight='bold')\\n\n",
    "plt.xticks(range(len(category_counts)), list(category_counts.keys()), rotation=45, ha='right')\\n\n",
    "plt.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars, category_counts.values())):\\n\n",
    "    plt.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de pastel para categor√≠as\\n\n",
    "plt.figure(figsize=(12, 8))\\n\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(category_counts)))\\n\n",
    "\\n\n",
    "wedges, texts, autotexts = plt.pie(list(category_counts.values()), labels=list(category_counts.keys()), \\n\n",
    "                                    autopct='%1.1f%%', colors=colors, startangle=90)\\n\n",
    "\\n\n",
    "plt.title('Distribuci√≥n de T√©rminos por Categor√≠a', fontsize=16, fontweight='bold')\\n\n",
    "plt.axis('equal')\\n\n",
    "\\n\n",
    "# Mejorar la legibilidad de las etiquetas\\n\n",
    "for autotext in autotexts:\\n\n",
    "    autotext.set_color('white')\\n\n",
    "    autotext.set_fontweight('bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. An√°lisis Temporal de T√©rminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Year a num√©rico\\n\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\\n\n",
    "\\n\n",
    "# An√°lisis temporal de t√©rminos\\n\n",
    "temporal_terms = {}\\n\n",
    "\\n\n",
    "for year in sorted(df['Year'].unique()):\\n\n",
    "    if pd.notna(year):\\n\n",
    "        year_data = df[df['Year'] == year]\\n\n",
    "        year_terms = []\\n\n",
    "        \\n\n",
    "        for terms in year_data['Title_Terms']:\\n\n",
    "            year_terms.extend(terms)\\n\n",
    "        for terms in year_data['Abstract_Terms']:\\n\n",
    "            year_terms.extend(terms)\\n\n",
    "        \\n\n",
    "        temporal_terms[year] = Counter(year_terms)\\n\n",
    "\\n\n",
    "print(\\\"=== EVOLUCI√ìN TEMPORAL DE T√âRMINOS ===\\\")\\n\n",
    "for year, term_counts in temporal_terms.items():\\n\n",
    "    print(f\\\"\\\\nA√±o {year}:\\\")\\n\n",
    "    for term, count in term_counts.most_common(5):\\n\n",
    "        print(f\\\"  {term}: {count} apariciones\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de evoluci√≥n temporal de t√©rminos principales\\n\n",
    "main_terms = ['artificial intelligence', 'machine learning', 'mathematics', 'education', 'k-12']\\n\n",
    "\\n\n",
    "plt.figure(figsize=(15, 8))\\n\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\\n\n",
    "\\n\n",
    "for i, term in enumerate(main_terms):\\n\n",
    "    term_counts = []\\n\n",
    "    years = []\\n\n",
    "    \\n\n",
    "    for year in sorted(temporal_terms.keys()):\\n\n",
    "        years.append(year)\\n\n",
    "        count = temporal_terms[year].get(term, 0)\\n\n",
    "        term_counts.append(count)\\n\n",
    "    \\n\n",
    "    \\n\n",
    "    plt.plot(years, term_counts, marker='o', linewidth=2, label=term, color=colors[i])\\n\n",
    "\\n\n",
    "plt.title('Evoluci√≥n Temporal de T√©rminos Principales', fontsize=16, fontweight='bold')\\n\n",
    "plt.xlabel('A√±o', fontsize=14)\\n\n",
    "plt.ylabel('Frecuencia', fontsize=14)\\n\n",
    "plt.legend(title='T√©rminos', bbox_to_anchor=(1.05, 1), loc='upper left')\\n\n",
    "plt.grid(True, alpha=0.3)\\n\n",
    "plt.xticks(rotation=45)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. An√°lisis de Co-ocurrencia de T√©rminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de co-ocurrencia de t√©rminos\\n\n",
    "co_occurrence = {}\\n\n",
    "\\n\n",
    "for _, row in df.iterrows():\\n\n",
    "    all_terms = row['Title_Terms'] + row['Abstract_Terms']\\n\n",
    "    \\n\n",
    "    for i, term1 in enumerate(all_terms):\\n\n",
    "        for j, term2 in enumerate(all_terms):\\n\n",
    "            if i < j:\\n\n",
    "                pair = tuple(sorted([term1, term2]))\\n\n",
    "                co_occurrence[pair] = co_occurrence.get(pair, 0) + 1\\n\n",
    "\\n\n",
    "# Top co-ocurrencias\\n\n",
    "top_co_occurrences = sorted(co_occurrence.items(), key=lambda x: x[1], reverse=True)[:15]\\n\n",
    "\\n\n",
    "print(\\\"=== TOP 15 CO-OCURRENCIAS DE T√âRMINOS ===\\\")\\n\n",
    "for i, ((term1, term2), count) in enumerate(top_co_occurrences, 1):\\n\n",
    "    print(f\\\"{i:2d}. {term1} + {term2}: {count} co-ocurrencias\\\")\\n\n",
    "\\n\n",
    "# Gr√°fico de co-ocurrencias\\n\n",
    "if top_co_occurrences:\\n\n",
    "    co_occurrence_df = pd.DataFrame(top_co_occurrences, columns=['Terms', 'Count'])\\n\n",
    "    co_occurrence_df['Term_Pair'] = [f\\\"{t1} + {t2}\\\" for (t1, t2) in co_occurrence_df['Terms']]\\n\n",
    "    \\n\n",
    "    plt.figure(figsize=(12, 8))\\n\n",
    "    bars = plt.barh(range(len(co_occurrence_df)), co_occurrence_df['Count'], color='lightblue', alpha=0.7)\\n\n",
    "    plt.yticks(range(len(co_occurrence_df)), co_occurrence_df['Term_Pair'], fontsize=10)\\n\n",
    "    plt.xlabel('N√∫mero de Co-ocurrencias', fontsize=14)\\n\n",
    "    plt.title('Top 15 Co-ocurrencias de T√©rminos', fontsize=16, fontweight='bold')\\n\n",
    "    plt.grid(True, alpha=0.3, axis='x')\\n\n",
    "    \\n\n",
    "    # Agregar valores en las barras\\n\n",
    "    for i, count in enumerate(co_occurrence_df['Count']):\\n\n",
    "        plt.text(count + 0.1, i, str(count), va='center', fontweight='bold')\\n\n",
    "    \\n\n",
    "    plt.tight_layout()\\n\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen ejecutivo\\n\n",
    "print(\\\"=== RESUMEN EJECUTIVO ===\\\\n\\\")\\n\n",
    "\\n\n",
    "print(f\\\"üìä Total de t√©rminos √∫nicos en t√≠tulos: {len(title_term_counts)}\\\")\\n\n",
    "print(f\\\"üìù Total de t√©rminos √∫nicos en abstracts: {len(abstract_term_counts)}\\\")\\n\n",
    "print(f\\\"üìà T√©rmino m√°s frecuente en t√≠tulos: {title_term_counts.most_common(1)[0][0]} ({title_term_counts.most_common(1)[0][1]} apariciones)\\\")\\n\n",
    "print(f\\\"üìâ T√©rmino m√°s frecuente en abstracts: {abstract_term_counts.most_common(1)[0][0]} ({abstract_term_counts.most_common(1)[0][1]} apariciones)\\\")\\n\n",
    "\\n\n",
    "# An√°lisis de categor√≠as\\n\n",
    "most_common_category = max(category_counts, key=category_counts.get)\\n\n",
    "print(f\\\"üèÜ Categor√≠a m√°s frecuente: {most_common_category} ({category_counts[most_common_category]} apariciones)\\\")\\n\n",
    "\\n\n",
    "# An√°lisis de co-ocurrencia\\n\n",
    "if top_co_occurrences:\\n\n",
    "    most_common_co_occurrence = top_co_occurrences[0]\\n\n",
    "    print(f\\\"üîó Co-ocurrencia m√°s frecuente: {most_common_co_occurrence[0][0]} + {most_common_co_occurrence[0][1]} ({most_common_co_occurrence[1]} veces)\\\")\\n\n",
    "\\n\n",
    "print(\\\"\\\\n=== CONCLUSIONES ===\\\")\\n\n",
    "print(\\\"1. Los t√©rminos de IA y ML dominan la literatura\\\")\\n\n",
    "print(\\\"2. Los t√©rminos educativos son fundamentales\\\")\\n\n",
    "print(\\\"3. Hay una evoluci√≥n temporal en el uso de t√©rminos\\\")\\n\n",
    "print(\\\"4. Existen patrones de co-ocurrencia significativos\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
