{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Términos de Búsqueda: Mapping Review IA y ML en Educación Matemática K-12\\n\n",
    "\\n\n",
    "**MQ6: ¿Qué términos de búsqueda se utilizan para definir la cadena de búsqueda en este tipo de estudios?**\\n\n",
    "\\n\n",
    "Este notebook analiza los términos de búsqueda y palabras clave utilizados en los estudios sobre IA y ML en educación matemática K-12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de dependencias\\n\n",
    "!pip install pandas numpy matplotlib seaborn plotly nltk wordcloud textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\\n\n",
    "import pandas as pd\\n\n",
    "import numpy as np\\n\n",
    "import matplotlib.pyplot as plt\\n\n",
    "import seaborn as sns\\n\n",
    "import plotly.express as px\\n\n",
    "import plotly.graph_objects as go\\n\n",
    "from plotly.subplots import make_subplots\\n\n",
    "import re\\n\n",
    "import nltk\\n\n",
    "from nltk.corpus import stopwords\\n\n",
    "from nltk.tokenize import word_tokenize\\n\n",
    "from collections import Counter\\n\n",
    "from wordcloud import WordCloud\\n\n",
    "from textblob import TextBlob\\n\n",
    "import warnings\\n\n",
    "warnings.filterwarnings('ignore')\\n\n",
    "\\n\n",
    "# Descargar recursos de NLTK\\n\n",
    "try:\\n\n",
    "    nltk.data.find('tokenizers/punkt')\\n\n",
    "except LookupError:\\n\n",
    "    nltk.download('punkt')\\n\n",
    "\\n\n",
    "try:\\n\n",
    "    nltk.data.find('corpora/stopwords')\\n\n",
    "except LookupError:\\n\n",
    "    nltk.download('stopwords')\\n\n",
    "\\n\n",
    "# Configuración de estilo\\n\n",
    "plt.style.use('seaborn-v0_8')\\n\n",
    "sns.set_palette(\\\"husl\\\")\\n\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\\n\n",
    "plt.rcParams['font.size'] = 12\\n\n",
    "\\n\n",
    "# Configuración para mostrar todas las columnas\\n\n",
    "pd.set_option('display.max_columns', None)\\n\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos desde GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset desde GitHub\\n\n",
    "# IMPORTANTE: Cambiar la URL por tu repositorio real\\n\n",
    "url = \\\"https://raw.githubusercontent.com/TU_USUARIO/TU_REPOSITORIO/main/MappingReview.csv\\\"\\n\n",
    "df = pd.read_csv(url, sep=';', encoding='utf-8')\\n\n",
    "\\n\n",
    "print(f\\\"Dataset cargado: {df.shape[0]} filas y {df.shape[1]} columnas\\\")\\n\n",
    "print(\\\"\\\\nPrimeras 5 filas:\\\")\\n\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis de Términos de Búsqueda (MQ6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer términos de búsqueda de títulos y abstracts\\n\n",
    "def extract_search_terms(text):\\n\n",
    "    if pd.isna(text):\\n\n",
    "        return []\\n\n",
    "    \\n\n",
    "    # Convertir a minúsculas\\n\n",
    "    text = str(text).lower()\\n\n",
    "    \\n\n",
    "    # Definir términos de búsqueda relevantes\\n\n",
    "    search_terms = [\\n\n",
    "        'artificial intelligence', 'ai', 'machine learning', 'ml', 'deep learning',\\n\n",
    "        'neural network', 'neural networks', 'intelligent tutoring system', 'its',\\n\n",
    "        'chatbot', 'chatbots', 'natural language processing', 'nlp',\\n\n",
    "        'computer vision', 'predictive analytics', 'data mining',\\n\n",
    "        'mathematics', 'math', 'mathematical', 'algebra', 'geometry', 'calculus',\\n\n",
    "        'k-12', 'k12', 'primary education', 'secondary education',\\n\n",
    "        'elementary', 'middle school', 'high school', 'primary school',\\n\n",
    "        'student', 'students', 'teacher', 'teachers', 'classroom',\\n\n",
    "        'learning', 'teaching', 'education', 'educational',\\n\n",
    "        'assessment', 'evaluation', 'performance', 'achievement',\\n\n",
    "        'personalized', 'adaptive', 'individualized', 'customized',\\n\n",
    "        'stem', 'science', 'technology', 'engineering',\\n\n",
    "        'digital', 'online', 'virtual', 'remote', 'distance learning'\\n\n",
    "    ]\\n\n",
    "    \\n\n",
    "    found_terms = []\\n\n",
    "    for term in search_terms:\\n\n",
    "        if term in text:\\n\n",
    "            found_terms.append(term)\\n\n",
    "    \\n\n",
    "    return found_terms\\n\n",
    "\\n\n",
    "# Aplicar extracción a títulos y abstracts\\n\n",
    "df['Title_Terms'] = df['Title'].apply(extract_search_terms)\\n\n",
    "df['Abstract_Terms'] = df['Abstract'].apply(extract_search_terms)\\n\n",
    "\\n\n",
    "print(\\\"Extracción de términos de búsqueda completada\\\")\\n\n",
    "print(f\\\"Publicaciones con términos en títulos: {len(df[df['Title_Terms'].apply(len) > 0])}\\\")\\n\n",
    "print(f\\\"Publicaciones con términos en abstracts: {len(df[df['Abstract_Terms'].apply(len) > 0])}\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de frecuencia de términos\\n\n",
    "all_title_terms = []\\n\n",
    "all_abstract_terms = []\\n\n",
    "\\n\n",
    "for terms in df['Title_Terms']:\\n\n",
    "    all_title_terms.extend(terms)\\n\n",
    "\\n\n",
    "for terms in df['Abstract_Terms']:\\n\n",
    "    all_abstract_terms.extend(terms)\\n\n",
    "\\n\n",
    "# Contar frecuencia\\n\n",
    "title_term_counts = Counter(all_title_terms)\\n\n",
    "abstract_term_counts = Counter(all_abstract_terms)\\n\n",
    "\\n\n",
    "print(\\\"=== TÉRMINOS MÁS FRECUENTES EN TÍTULOS ===\\\")\\n\n",
    "for term, count in title_term_counts.most_common(15):\\n\n",
    "    print(f\\\"{term}: {count} apariciones\\\")\\n\n",
    "\\n\n",
    "print(\\\"\\\\n=== TÉRMINOS MÁS FRECUENTES EN ABSTRACTS ===\\\")\\n\n",
    "for term, count in abstract_term_counts.most_common(15):\\n\n",
    "    print(f\\\"{term}: {count} apariciones\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras para términos más frecuentes\\n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\\n\n",
    "\\n\n",
    "# Términos en títulos\\n\n",
    "top_title_terms = dict(title_term_counts.most_common(10))\\n\n",
    "bars1 = ax1.bar(range(len(top_title_terms)), top_title_terms.values(), color='lightblue', alpha=0.7)\\n\n",
    "ax1.set_xlabel('Términos de Búsqueda', fontsize=14)\\n\n",
    "ax1.set_ylabel('Frecuencia', fontsize=14)\\n\n",
    "ax1.set_title('Términos Más Frecuentes en Títulos', fontsize=16, fontweight='bold')\\n\n",
    "ax1.set_xticks(range(len(top_title_terms)))\\n\n",
    "ax1.set_xticklabels(top_title_terms.keys(), rotation=45, ha='right')\\n\n",
    "ax1.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars1, top_title_terms.values())):\\n\n",
    "    ax1.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "# Términos en abstracts\\n\n",
    "top_abstract_terms = dict(abstract_term_counts.most_common(10))\\n\n",
    "bars2 = ax2.bar(range(len(top_abstract_terms)), top_abstract_terms.values(), color='lightcoral', alpha=0.7)\\n\n",
    "ax2.set_xlabel('Términos de Búsqueda', fontsize=14)\\n\n",
    "ax2.set_ylabel('Frecuencia', fontsize=14)\\n\n",
    "ax2.set_title('Términos Más Frecuentes en Abstracts', fontsize=16, fontweight='bold')\\n\n",
    "ax2.set_xticks(range(len(top_abstract_terms)))\\n\n",
    "ax2.set_xticklabels(top_abstract_terms.keys(), rotation=45, ha='right')\\n\n",
    "ax2.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars2, top_abstract_terms.values())):\\n\n",
    "    ax2.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis de Palabras Clave y Nubes de Palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar texto para nube de palabras\\n\n",
    "def clean_text_for_wordcloud(text):\\n\n",
    "    if pd.isna(text):\\n\n",
    "        return ''\\n\n",
    "    \\n\n",
    "    # Convertir a minúsculas\\n\n",
    "    text = str(text).lower()\\n\n",
    "    \\n\n",
    "    # Remover caracteres especiales\\n\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\\n\n",
    "    \\n\n",
    "    # Tokenizar\\n\n",
    "    tokens = word_tokenize(text)\\n\n",
    "    \\n\n",
    "    # Remover stopwords\\n\n",
    "    stop_words = set(stopwords.words('english'))\\n\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\\n\n",
    "    \\n\n",
    "    return ' '.join(tokens)\\n\n",
    "\\n\n",
    "# Crear texto combinado para nube de palabras\\n\n",
    "all_titles = ' '.join(df['Title'].fillna('').astype(str))\\n\n",
    "all_abstracts = ' '.join(df['Abstract'].fillna('').astype(str))\\n\n",
    "\\n\n",
    "# Limpiar texto\\n\n",
    "clean_titles = clean_text_for_wordcloud(all_titles)\\n\n",
    "clean_abstracts = clean_text_for_wordcloud(all_abstracts)\\n\n",
    "\\n\n",
    "print(\\\"Texto procesado para nubes de palabras\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar nubes de palabras\\n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\\n\n",
    "\\n\n",
    "# Nube de palabras para títulos\\n\n",
    "wordcloud_titles = WordCloud(width=800, height=400, background_color='white', \\n\n",
    "                            max_words=100, colormap='viridis').generate(clean_titles)\\n\n",
    "ax1.imshow(wordcloud_titles, interpolation='bilinear')\\n\n",
    "ax1.axis('off')\\n\n",
    "ax1.set_title('Nube de Palabras - Títulos', fontsize=16, fontweight='bold')\\n\n",
    "\\n\n",
    "# Nube de palabras para abstracts\\n\n",
    "wordcloud_abstracts = WordCloud(width=800, height=400, background_color='white', \\n\n",
    "                               max_words=100, colormap='plasma').generate(clean_abstracts)\\n\n",
    "ax2.imshow(wordcloud_abstracts, interpolation='bilinear')\\n\n",
    "ax2.axis('off')\\n\n",
    "ax2.set_title('Nube de Palabras - Abstracts', fontsize=16, fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de Categorías de Términos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir categorías de términos\\n\n",
    "term_categories = {\\n\n",
    "    'AI_ML': ['artificial intelligence', 'ai', 'machine learning', 'ml', 'deep learning', 'neural network', 'neural networks'],\\n\n",
    "    'Education': ['education', 'educational', 'learning', 'teaching', 'student', 'students', 'teacher', 'teachers', 'classroom'],\\n\n",
    "    'Mathematics': ['mathematics', 'math', 'mathematical', 'algebra', 'geometry', 'calculus'],\\n\n",
    "    'K12': ['k-12', 'k12', 'primary education', 'secondary education', 'elementary', 'middle school', 'high school', 'primary school'],\\n\n",
    "    'Technology': ['intelligent tutoring system', 'its', 'chatbot', 'chatbots', 'natural language processing', 'nlp', 'computer vision'],\\n\n",
    "    'Assessment': ['assessment', 'evaluation', 'performance', 'achievement'],\\n\n",
    "    'Personalization': ['personalized', 'adaptive', 'individualized', 'customized'],\\n\n",
    "    'STEM': ['stem', 'science', 'technology', 'engineering'],\\n\n",
    "    'Digital': ['digital', 'online', 'virtual', 'remote', 'distance learning']\\n\n",
    "}\\n\n",
    "\\n\n",
    "# Contar términos por categoría\\n\n",
    "category_counts = {}\\n\n",
    "for category, terms in term_categories.items():\\n\n",
    "    count = 0\\n\n",
    "    for term in terms:\\n\n",
    "        count += title_term_counts.get(term, 0) + abstract_term_counts.get(term, 0)\\n\n",
    "    category_counts[category] = count\\n\n",
    "\\n\n",
    "print(\\\"=== FRECUENCIA POR CATEGORÍA DE TÉRMINOS ===\\\")\\n\n",
    "for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\\n\n",
    "    print(f\\\"{category}: {count} apariciones\\\")\\n\n",
    "\\n\n",
    "# Gráfico de barras para categorías\\n\n",
    "plt.figure(figsize=(12, 8))\\n\n",
    "bars = plt.bar(range(len(category_counts)), list(category_counts.values()), color='lightgreen', alpha=0.7)\\n\n",
    "plt.xlabel('Categoría de Términos', fontsize=14)\\n\n",
    "plt.ylabel('Frecuencia Total', fontsize=14)\\n\n",
    "plt.title('Frecuencia de Términos por Categoría', fontsize=16, fontweight='bold')\\n\n",
    "plt.xticks(range(len(category_counts)), list(category_counts.keys()), rotation=45, ha='right')\\n\n",
    "plt.grid(True, alpha=0.3, axis='y')\\n\n",
    "\\n\n",
    "# Agregar valores en las barras\\n\n",
    "for i, (bar, count) in enumerate(zip(bars, category_counts.values())):\\n\n",
    "    plt.text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de pastel para categorías\\n\n",
    "plt.figure(figsize=(12, 8))\\n\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(category_counts)))\\n\n",
    "\\n\n",
    "wedges, texts, autotexts = plt.pie(list(category_counts.values()), labels=list(category_counts.keys()), \\n\n",
    "                                    autopct='%1.1f%%', colors=colors, startangle=90)\\n\n",
    "\\n\n",
    "plt.title('Distribución de Términos por Categoría', fontsize=16, fontweight='bold')\\n\n",
    "plt.axis('equal')\\n\n",
    "\\n\n",
    "# Mejorar la legibilidad de las etiquetas\\n\n",
    "for autotext in autotexts:\\n\n",
    "    autotext.set_color('white')\\n\n",
    "    autotext.set_fontweight('bold')\\n\n",
    "\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis Temporal de Términos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Year a numérico\\n\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\\n\n",
    "\\n\n",
    "# Análisis temporal de términos\\n\n",
    "temporal_terms = {}\\n\n",
    "\\n\n",
    "for year in sorted(df['Year'].unique()):\\n\n",
    "    if pd.notna(year):\\n\n",
    "        year_data = df[df['Year'] == year]\\n\n",
    "        year_terms = []\\n\n",
    "        \\n\n",
    "        for terms in year_data['Title_Terms']:\\n\n",
    "            year_terms.extend(terms)\\n\n",
    "        for terms in year_data['Abstract_Terms']:\\n\n",
    "            year_terms.extend(terms)\\n\n",
    "        \\n\n",
    "        temporal_terms[year] = Counter(year_terms)\\n\n",
    "\\n\n",
    "print(\\\"=== EVOLUCIÓN TEMPORAL DE TÉRMINOS ===\\\")\\n\n",
    "for year, term_counts in temporal_terms.items():\\n\n",
    "    print(f\\\"\\\\nAño {year}:\\\")\\n\n",
    "    for term, count in term_counts.most_common(5):\\n\n",
    "        print(f\\\"  {term}: {count} apariciones\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de evolución temporal de términos principales\\n\n",
    "main_terms = ['artificial intelligence', 'machine learning', 'mathematics', 'education', 'k-12']\\n\n",
    "\\n\n",
    "plt.figure(figsize=(15, 8))\\n\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\\n\n",
    "\\n\n",
    "for i, term in enumerate(main_terms):\\n\n",
    "    term_counts = []\\n\n",
    "    years = []\\n\n",
    "    \\n\n",
    "    for year in sorted(temporal_terms.keys()):\\n\n",
    "        years.append(year)\\n\n",
    "        count = temporal_terms[year].get(term, 0)\\n\n",
    "        term_counts.append(count)\\n\n",
    "    \\n\n",
    "    \\n\n",
    "    plt.plot(years, term_counts, marker='o', linewidth=2, label=term, color=colors[i])\\n\n",
    "\\n\n",
    "plt.title('Evolución Temporal de Términos Principales', fontsize=16, fontweight='bold')\\n\n",
    "plt.xlabel('Año', fontsize=14)\\n\n",
    "plt.ylabel('Frecuencia', fontsize=14)\\n\n",
    "plt.legend(title='Términos', bbox_to_anchor=(1.05, 1), loc='upper left')\\n\n",
    "plt.grid(True, alpha=0.3)\\n\n",
    "plt.xticks(rotation=45)\\n\n",
    "plt.tight_layout()\\n\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis de Co-ocurrencia de Términos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de co-ocurrencia de términos\\n\n",
    "co_occurrence = {}\\n\n",
    "\\n\n",
    "for _, row in df.iterrows():\\n\n",
    "    all_terms = row['Title_Terms'] + row['Abstract_Terms']\\n\n",
    "    \\n\n",
    "    for i, term1 in enumerate(all_terms):\\n\n",
    "        for j, term2 in enumerate(all_terms):\\n\n",
    "            if i < j:\\n\n",
    "                pair = tuple(sorted([term1, term2]))\\n\n",
    "                co_occurrence[pair] = co_occurrence.get(pair, 0) + 1\\n\n",
    "\\n\n",
    "# Top co-ocurrencias\\n\n",
    "top_co_occurrences = sorted(co_occurrence.items(), key=lambda x: x[1], reverse=True)[:15]\\n\n",
    "\\n\n",
    "print(\\\"=== TOP 15 CO-OCURRENCIAS DE TÉRMINOS ===\\\")\\n\n",
    "for i, ((term1, term2), count) in enumerate(top_co_occurrences, 1):\\n\n",
    "    print(f\\\"{i:2d}. {term1} + {term2}: {count} co-ocurrencias\\\")\\n\n",
    "\\n\n",
    "# Gráfico de co-ocurrencias\\n\n",
    "if top_co_occurrences:\\n\n",
    "    co_occurrence_df = pd.DataFrame(top_co_occurrences, columns=['Terms', 'Count'])\\n\n",
    "    co_occurrence_df['Term_Pair'] = [f\\\"{t1} + {t2}\\\" for (t1, t2) in co_occurrence_df['Terms']]\\n\n",
    "    \\n\n",
    "    plt.figure(figsize=(12, 8))\\n\n",
    "    bars = plt.barh(range(len(co_occurrence_df)), co_occurrence_df['Count'], color='lightblue', alpha=0.7)\\n\n",
    "    plt.yticks(range(len(co_occurrence_df)), co_occurrence_df['Term_Pair'], fontsize=10)\\n\n",
    "    plt.xlabel('Número de Co-ocurrencias', fontsize=14)\\n\n",
    "    plt.title('Top 15 Co-ocurrencias de Términos', fontsize=16, fontweight='bold')\\n\n",
    "    plt.grid(True, alpha=0.3, axis='x')\\n\n",
    "    \\n\n",
    "    # Agregar valores en las barras\\n\n",
    "    for i, count in enumerate(co_occurrence_df['Count']):\\n\n",
    "        plt.text(count + 0.1, i, str(count), va='center', fontweight='bold')\\n\n",
    "    \\n\n",
    "    plt.tight_layout()\\n\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen ejecutivo\\n\n",
    "print(\\\"=== RESUMEN EJECUTIVO ===\\\\n\\\")\\n\n",
    "\\n\n",
    "print(f\\\"📊 Total de términos únicos en títulos: {len(title_term_counts)}\\\")\\n\n",
    "print(f\\\"📝 Total de términos únicos en abstracts: {len(abstract_term_counts)}\\\")\\n\n",
    "print(f\\\"📈 Término más frecuente en títulos: {title_term_counts.most_common(1)[0][0]} ({title_term_counts.most_common(1)[0][1]} apariciones)\\\")\\n\n",
    "print(f\\\"📉 Término más frecuente en abstracts: {abstract_term_counts.most_common(1)[0][0]} ({abstract_term_counts.most_common(1)[0][1]} apariciones)\\\")\\n\n",
    "\\n\n",
    "# Análisis de categorías\\n\n",
    "most_common_category = max(category_counts, key=category_counts.get)\\n\n",
    "print(f\\\"🏆 Categoría más frecuente: {most_common_category} ({category_counts[most_common_category]} apariciones)\\\")\\n\n",
    "\\n\n",
    "# Análisis de co-ocurrencia\\n\n",
    "if top_co_occurrences:\\n\n",
    "    most_common_co_occurrence = top_co_occurrences[0]\\n\n",
    "    print(f\\\"🔗 Co-ocurrencia más frecuente: {most_common_co_occurrence[0][0]} + {most_common_co_occurrence[0][1]} ({most_common_co_occurrence[1]} veces)\\\")\\n\n",
    "\\n\n",
    "print(\\\"\\\\n=== CONCLUSIONES ===\\\")\\n\n",
    "print(\\\"1. Los términos de IA y ML dominan la literatura\\\")\\n\n",
    "print(\\\"2. Los términos educativos son fundamentales\\\")\\n\n",
    "print(\\\"3. Hay una evolución temporal en el uso de términos\\\")\\n\n",
    "print(\\\"4. Existen patrones de co-ocurrencia significativos\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
